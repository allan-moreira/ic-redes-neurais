{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:20:22.198604: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-11 00:20:23.136438: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-11 00:20:30.086753: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-11 00:20:30.086810: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-11 00:20:31.650004: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 00:20:34.033693: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-11 00:20:34.034789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 00:20:38.284525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import fabs\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo algumas variáveis\n",
    "saidas = ['DOMPRECDOMEXP', 'DOMPRECRESEXP', 'ADENSEXCDOMEXP', 'ADENSEXCRESEXP',\t'ONUSEXCDOMEXP', 'ONUSEXCRESEXP', 'COABFAMDOMEXP', 'COABFAMRESEXP']\n",
    "saidasDomicilios = ['DOMPRECDOMEXP', 'ADENSEXCDOMEXP', 'ONUSEXCDOMEXP', 'COABFAMDOMEXP']\n",
    "saidasDesidentes = ['DOMPRECRESEXP', 'ADENSEXCRESEXP', 'ONUSEXCRESEXP', 'COABFAMRESEXP']\n",
    "domiciliosPrecarios = ['DOMPRECDOMEXP']\n",
    "adensamentoExcessivo = ['ADENSEXCDOMEXP']\n",
    "onusExcessivo = ['ONUSEXCDOMEXP']\n",
    "coabtaçãoFamiliar = ['COABFAMDOMEXP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dim.1</th>\n",
       "      <th>Dim.2</th>\n",
       "      <th>Dim.3</th>\n",
       "      <th>Dim.4</th>\n",
       "      <th>Dim.5</th>\n",
       "      <th>DOMPRECDOMEXP</th>\n",
       "      <th>ADENSEXCDOMEXP</th>\n",
       "      <th>ONUSEXCDOMEXP</th>\n",
       "      <th>COABFAMDOMEXP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.255267</td>\n",
       "      <td>1.636565</td>\n",
       "      <td>-0.734032</td>\n",
       "      <td>0.249567</td>\n",
       "      <td>-0.490873</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>308.77</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.902284</td>\n",
       "      <td>-0.905511</td>\n",
       "      <td>-0.164092</td>\n",
       "      <td>-0.336964</td>\n",
       "      <td>-0.130283</td>\n",
       "      <td>11.43</td>\n",
       "      <td>126.68</td>\n",
       "      <td>333.07</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.514829</td>\n",
       "      <td>-0.457965</td>\n",
       "      <td>0.832445</td>\n",
       "      <td>-0.888344</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>78.55</td>\n",
       "      <td>39.05</td>\n",
       "      <td>111.92</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383952</td>\n",
       "      <td>0.202920</td>\n",
       "      <td>-0.351442</td>\n",
       "      <td>0.387851</td>\n",
       "      <td>0.348902</td>\n",
       "      <td>20.22</td>\n",
       "      <td>138.96</td>\n",
       "      <td>496.56</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.425747</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>-0.249719</td>\n",
       "      <td>0.413795</td>\n",
       "      <td>0.236795</td>\n",
       "      <td>8.57</td>\n",
       "      <td>120.49</td>\n",
       "      <td>373.83</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-2.160979</td>\n",
       "      <td>-0.774764</td>\n",
       "      <td>2.681624</td>\n",
       "      <td>-1.242698</td>\n",
       "      <td>-0.451944</td>\n",
       "      <td>22.77</td>\n",
       "      <td>88.48</td>\n",
       "      <td>52.31</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>3.486756</td>\n",
       "      <td>1.296490</td>\n",
       "      <td>0.961841</td>\n",
       "      <td>-1.467687</td>\n",
       "      <td>1.530743</td>\n",
       "      <td>19.36</td>\n",
       "      <td>64.34</td>\n",
       "      <td>313.49</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>-3.217481</td>\n",
       "      <td>0.661316</td>\n",
       "      <td>-0.593865</td>\n",
       "      <td>0.031387</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.27</td>\n",
       "      <td>157.44</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>-1.105044</td>\n",
       "      <td>0.994186</td>\n",
       "      <td>-0.674440</td>\n",
       "      <td>-0.233511</td>\n",
       "      <td>-0.088889</td>\n",
       "      <td>47.05</td>\n",
       "      <td>21.22</td>\n",
       "      <td>390.45</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0.313055</td>\n",
       "      <td>-0.680279</td>\n",
       "      <td>0.117782</td>\n",
       "      <td>-0.932248</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.92</td>\n",
       "      <td>261.08</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dim.1     Dim.2     Dim.3     Dim.4     Dim.5  DOMPRECDOMEXP  \\\n",
       "0   -4.255267  1.636565 -0.734032  0.249567 -0.490873           9.55   \n",
       "1   -0.902284 -0.905511 -0.164092 -0.336964 -0.130283          11.43   \n",
       "2   -3.514829 -0.457965  0.832445 -0.888344  0.783307          78.55   \n",
       "3    0.383952  0.202920 -0.351442  0.387851  0.348902          20.22   \n",
       "4   -1.425747  0.337700 -0.249719  0.413795  0.236795           8.57   \n",
       "..        ...       ...       ...       ...       ...            ...   \n",
       "898 -2.160979 -0.774764  2.681624 -1.242698 -0.451944          22.77   \n",
       "899  3.486756  1.296490  0.961841 -1.467687  1.530743          19.36   \n",
       "900 -3.217481  0.661316 -0.593865  0.031387  0.020535           0.00   \n",
       "901 -1.105044  0.994186 -0.674440 -0.233511 -0.088889          47.05   \n",
       "902  0.313055 -0.680279  0.117782 -0.932248  0.688112           0.00   \n",
       "\n",
       "     ADENSEXCDOMEXP  ONUSEXCDOMEXP  COABFAMDOMEXP  \n",
       "0              0.00         308.77             90  \n",
       "1            126.68         333.07            686  \n",
       "2             39.05         111.92            235  \n",
       "3            138.96         496.56            484  \n",
       "4            120.49         373.83            337  \n",
       "..              ...            ...            ...  \n",
       "898           88.48          52.31            480  \n",
       "899           64.34         313.49            881  \n",
       "900           76.27         157.44            389  \n",
       "901           21.22         390.45            670  \n",
       "902          117.92         261.08            862  \n",
       "\n",
       "[903 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa os dados\n",
    "deficit_data_y = pd.read_excel('Banco_903_Amostras_Completo.xlsx')[saidasDomicilios]\n",
    "deficit_data_x = pd.read_excel('Dimensoes_PCA_903_Amostras.xlsx')\n",
    "\n",
    "# Concatena os dois blocos horizontalmente\n",
    "deficit_data = pd.concat([deficit_data_x, deficit_data_y], axis=1)\n",
    "\n",
    "# Exibe o banco de dados\n",
    "deficit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embaralha a ordem das amostras e divide em blocos de treino (80%) e validação (20%)\n",
    "train, validation = train_test_split(deficit_data, test_size=0.2, random_state=randint(0, 100))\n",
    "\n",
    "# Separando as variáveis explicativas das variáveis resposta\n",
    "train_x = train.drop(columns=saidasDomicilios)\n",
    "validation_x = validation.drop(columns=saidasDomicilios)\n",
    "train_y = train[saidasDomicilios]\n",
    "validation_y = validation[saidasDomicilios]\n",
    "\n",
    "# Separa uma parte do bloco de teste\n",
    "numLines = int(validation_x.shape[0] * 0.25) #Equivalente a aproximadamente 5% do banco de dados\n",
    "validation_x, test_x = validation_x[:numLines], validation_x[numLines:]\n",
    "validation_y, test_y = validation_y[:numLines], validation_y[numLines:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:20:44.567517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-11 00:20:44.567991: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Inicializa a rede neural\n",
    "neuralNetwork = Sequential()\n",
    "neuralNetwork.add(Dense(units = 24, activation = 'relu', input_dim = validation_x.shape[1]))\n",
    "neuralNetwork.add(Dense(units = train_y.shape[1], activation = 'linear'))\n",
    "neuralNetwork.compile(loss = 'huber', optimizer = 'rmsprop', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 309.2913 - mae: 309.7877 - val_loss: 358.8185 - val_mae: 359.3175\n",
      "Epoch 2/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 308.9684 - mae: 309.4666 - val_loss: 358.4959 - val_mae: 358.9932\n",
      "Epoch 3/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 308.6649 - mae: 309.1642 - val_loss: 358.1606 - val_mae: 358.6597\n",
      "Epoch 4/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 308.3461 - mae: 308.8457 - val_loss: 357.8079 - val_mae: 358.3078\n",
      "Epoch 5/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 308.0092 - mae: 308.5090 - val_loss: 357.4339 - val_mae: 357.9339\n",
      "Epoch 6/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 307.6428 - mae: 308.1426 - val_loss: 357.0241 - val_mae: 357.5241\n",
      "Epoch 7/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 307.2493 - mae: 307.7493 - val_loss: 356.5923 - val_mae: 357.0923\n",
      "Epoch 8/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 306.8332 - mae: 307.3329 - val_loss: 356.1208 - val_mae: 356.6208\n",
      "Epoch 9/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 306.3833 - mae: 306.8831 - val_loss: 355.6243 - val_mae: 356.1243\n",
      "Epoch 10/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 305.8994 - mae: 306.3989 - val_loss: 355.0621 - val_mae: 355.5621\n",
      "Epoch 11/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 305.3759 - mae: 305.8747 - val_loss: 354.4721 - val_mae: 354.9713\n",
      "Epoch 12/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 304.8255 - mae: 305.3247 - val_loss: 353.8419 - val_mae: 354.3407\n",
      "Epoch 13/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 304.2422 - mae: 304.7415 - val_loss: 353.1730 - val_mae: 353.6711\n",
      "Epoch 14/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 303.6244 - mae: 304.1231 - val_loss: 352.4743 - val_mae: 352.9723\n",
      "Epoch 15/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 302.9864 - mae: 303.4847 - val_loss: 351.7473 - val_mae: 352.2469\n",
      "Epoch 16/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 302.3208 - mae: 302.8199 - val_loss: 350.9760 - val_mae: 351.4732\n",
      "Epoch 17/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 301.6269 - mae: 302.1260 - val_loss: 350.1537 - val_mae: 350.6533\n",
      "Epoch 18/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 300.8929 - mae: 301.3911 - val_loss: 349.2957 - val_mae: 349.7935\n",
      "Epoch 19/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 300.1289 - mae: 300.6281 - val_loss: 348.3815 - val_mae: 348.8814\n",
      "Epoch 20/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 299.3293 - mae: 299.8286 - val_loss: 347.4671 - val_mae: 347.9671\n",
      "Epoch 21/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 298.5173 - mae: 299.0161 - val_loss: 346.4976 - val_mae: 346.9974\n",
      "Epoch 22/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 297.6654 - mae: 298.1642 - val_loss: 345.4792 - val_mae: 345.9760\n",
      "Epoch 23/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 296.7869 - mae: 297.2860 - val_loss: 344.4368 - val_mae: 344.9363\n",
      "Epoch 24/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 295.8870 - mae: 296.3866 - val_loss: 343.3919 - val_mae: 343.8919\n",
      "Epoch 25/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 294.9646 - mae: 295.4633 - val_loss: 342.3565 - val_mae: 342.8550\n",
      "Epoch 26/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 294.0286 - mae: 294.5269 - val_loss: 341.3465 - val_mae: 341.8441\n",
      "Epoch 27/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 293.0732 - mae: 293.5714 - val_loss: 340.2935 - val_mae: 340.7935\n",
      "Epoch 28/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 292.0892 - mae: 292.5876 - val_loss: 339.2005 - val_mae: 339.7005\n",
      "Epoch 29/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 291.0900 - mae: 291.5881 - val_loss: 338.0739 - val_mae: 338.5731\n",
      "Epoch 30/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 290.0702 - mae: 290.5687 - val_loss: 336.9492 - val_mae: 337.4479\n",
      "Epoch 31/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 289.0422 - mae: 289.5406 - val_loss: 335.7961 - val_mae: 336.2961\n",
      "Epoch 32/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 287.9877 - mae: 288.4866 - val_loss: 334.6264 - val_mae: 335.1252\n",
      "Epoch 33/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 286.9203 - mae: 287.4193 - val_loss: 333.4077 - val_mae: 333.9071\n",
      "Epoch 34/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 285.8309 - mae: 286.3294 - val_loss: 332.1638 - val_mae: 332.6634\n",
      "Epoch 35/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 284.7265 - mae: 285.2251 - val_loss: 330.9252 - val_mae: 331.4249\n",
      "Epoch 36/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 283.6032 - mae: 284.1015 - val_loss: 329.6952 - val_mae: 330.1932\n",
      "Epoch 37/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 282.4584 - mae: 282.9571 - val_loss: 328.4670 - val_mae: 328.9644\n",
      "Epoch 38/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 281.2887 - mae: 281.7876 - val_loss: 327.2163 - val_mae: 327.7148\n",
      "Epoch 39/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 280.1061 - mae: 280.6048 - val_loss: 325.9381 - val_mae: 326.4361\n",
      "Epoch 40/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 278.9097 - mae: 279.4085 - val_loss: 324.6669 - val_mae: 325.1619\n",
      "Epoch 41/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 277.7109 - mae: 278.2096 - val_loss: 323.3892 - val_mae: 323.8830\n",
      "Epoch 42/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 276.5118 - mae: 277.0104 - val_loss: 322.0800 - val_mae: 322.5755\n",
      "Epoch 43/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 275.2705 - mae: 275.7693 - val_loss: 320.7863 - val_mae: 321.2833\n",
      "Epoch 44/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 274.0334 - mae: 274.5316 - val_loss: 319.4916 - val_mae: 319.9901\n",
      "Epoch 45/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 272.8114 - mae: 273.3101 - val_loss: 318.1791 - val_mae: 318.6779\n",
      "Epoch 46/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 271.5761 - mae: 272.0746 - val_loss: 316.8537 - val_mae: 317.3510\n",
      "Epoch 47/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 270.3140 - mae: 270.8122 - val_loss: 315.5320 - val_mae: 316.0299\n",
      "Epoch 48/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 269.0445 - mae: 269.5427 - val_loss: 314.1765 - val_mae: 314.6759\n",
      "Epoch 49/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 267.7630 - mae: 268.2612 - val_loss: 312.7955 - val_mae: 313.2952\n",
      "Epoch 50/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 266.4690 - mae: 266.9673 - val_loss: 311.4200 - val_mae: 311.9163\n",
      "Epoch 51/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 265.1587 - mae: 265.6572 - val_loss: 310.0219 - val_mae: 310.5217\n",
      "Epoch 52/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 263.8247 - mae: 264.3228 - val_loss: 308.6013 - val_mae: 309.1012\n",
      "Epoch 53/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 262.4825 - mae: 262.9811 - val_loss: 307.1677 - val_mae: 307.6675\n",
      "Epoch 54/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 261.1323 - mae: 261.6310 - val_loss: 305.7184 - val_mae: 306.2169\n",
      "Epoch 55/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 259.7824 - mae: 260.2812 - val_loss: 304.2491 - val_mae: 304.7491\n",
      "Epoch 56/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 258.3954 - mae: 258.8941 - val_loss: 302.7015 - val_mae: 303.2010\n",
      "Epoch 57/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 257.0078 - mae: 257.5062 - val_loss: 301.2066 - val_mae: 301.7047\n",
      "Epoch 58/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 255.6019 - mae: 256.1004 - val_loss: 299.6795 - val_mae: 300.1776\n",
      "Epoch 59/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 254.2045 - mae: 254.7032 - val_loss: 298.1882 - val_mae: 298.6857\n",
      "Epoch 60/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 252.8232 - mae: 253.3215 - val_loss: 296.6427 - val_mae: 297.1404\n",
      "Epoch 61/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 251.4459 - mae: 251.9441 - val_loss: 295.0971 - val_mae: 295.5961\n",
      "Epoch 62/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 250.0301 - mae: 250.5285 - val_loss: 293.4920 - val_mae: 293.9918\n",
      "Epoch 63/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 248.6076 - mae: 249.1058 - val_loss: 291.8867 - val_mae: 292.3866\n",
      "Epoch 64/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 247.1968 - mae: 247.6951 - val_loss: 290.2802 - val_mae: 290.7802\n",
      "Epoch 65/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 245.7689 - mae: 246.2672 - val_loss: 288.6393 - val_mae: 289.1392\n",
      "Epoch 66/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 244.3390 - mae: 244.8374 - val_loss: 287.0114 - val_mae: 287.5096\n",
      "Epoch 67/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 242.9053 - mae: 243.4036 - val_loss: 285.4277 - val_mae: 285.9270\n",
      "Epoch 68/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 241.4735 - mae: 241.9719 - val_loss: 283.8250 - val_mae: 284.3239\n",
      "Epoch 69/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 240.0608 - mae: 240.5589 - val_loss: 282.2994 - val_mae: 282.7978\n",
      "Epoch 70/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 238.6425 - mae: 239.1405 - val_loss: 280.7169 - val_mae: 281.2133\n",
      "Epoch 71/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 237.2192 - mae: 237.7172 - val_loss: 279.0925 - val_mae: 279.5890\n",
      "Epoch 72/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 235.7990 - mae: 236.2975 - val_loss: 277.4672 - val_mae: 277.9646\n",
      "Epoch 73/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 234.3880 - mae: 234.8868 - val_loss: 275.8078 - val_mae: 276.3060\n",
      "Epoch 74/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 232.9828 - mae: 233.4810 - val_loss: 274.1603 - val_mae: 274.6589\n",
      "Epoch 75/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 231.5748 - mae: 232.0732 - val_loss: 272.4289 - val_mae: 272.9279\n",
      "Epoch 76/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 230.1860 - mae: 230.6846 - val_loss: 270.7347 - val_mae: 271.2331\n",
      "Epoch 77/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 228.7994 - mae: 229.2974 - val_loss: 269.0085 - val_mae: 269.5078\n",
      "Epoch 78/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 227.4189 - mae: 227.9169 - val_loss: 267.2915 - val_mae: 267.7912\n",
      "Epoch 79/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 226.0200 - mae: 226.5183 - val_loss: 265.6759 - val_mae: 266.1756\n",
      "Epoch 80/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 224.6406 - mae: 225.1385 - val_loss: 264.0384 - val_mae: 264.5383\n",
      "Epoch 81/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 223.2418 - mae: 223.7398 - val_loss: 262.3315 - val_mae: 262.8309\n",
      "Epoch 82/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 221.8428 - mae: 222.3406 - val_loss: 260.6913 - val_mae: 261.1913\n",
      "Epoch 83/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 220.4662 - mae: 220.9639 - val_loss: 258.9949 - val_mae: 259.4949\n",
      "Epoch 84/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 219.0738 - mae: 219.5719 - val_loss: 257.2755 - val_mae: 257.7745\n",
      "Epoch 85/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 217.6631 - mae: 218.1612 - val_loss: 255.5187 - val_mae: 256.0172\n",
      "Epoch 86/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 216.2290 - mae: 216.7273 - val_loss: 253.8531 - val_mae: 254.3531\n",
      "Epoch 87/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 214.8268 - mae: 215.3253 - val_loss: 252.1671 - val_mae: 252.6665\n",
      "Epoch 88/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 213.3922 - mae: 213.8905 - val_loss: 250.4832 - val_mae: 250.9832\n",
      "Epoch 89/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 211.9557 - mae: 212.4538 - val_loss: 248.8024 - val_mae: 249.3017\n",
      "Epoch 90/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 210.5118 - mae: 211.0100 - val_loss: 247.1270 - val_mae: 247.6266\n",
      "Epoch 91/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 209.0987 - mae: 209.5970 - val_loss: 245.4072 - val_mae: 245.9072\n",
      "Epoch 92/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 207.6453 - mae: 208.1433 - val_loss: 243.7252 - val_mae: 244.2225\n",
      "Epoch 93/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 206.1882 - mae: 206.6859 - val_loss: 242.0106 - val_mae: 242.5106\n",
      "Epoch 94/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 204.7179 - mae: 205.2160 - val_loss: 240.2347 - val_mae: 240.7346\n",
      "Epoch 95/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 203.2557 - mae: 203.7532 - val_loss: 238.5050 - val_mae: 239.0050\n",
      "Epoch 96/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 201.7886 - mae: 202.2868 - val_loss: 236.7177 - val_mae: 237.2177\n",
      "Epoch 97/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 200.3046 - mae: 200.8021 - val_loss: 234.8886 - val_mae: 235.3886\n",
      "Epoch 98/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 198.8151 - mae: 199.3134 - val_loss: 233.0811 - val_mae: 233.5807\n",
      "Epoch 99/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 197.3457 - mae: 197.8436 - val_loss: 231.3568 - val_mae: 231.8564\n",
      "Epoch 100/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 195.8911 - mae: 196.3894 - val_loss: 229.6080 - val_mae: 230.1079\n",
      "Epoch 101/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 194.4319 - mae: 194.9297 - val_loss: 227.8461 - val_mae: 228.3460\n",
      "Epoch 102/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 192.9750 - mae: 193.4733 - val_loss: 226.0355 - val_mae: 226.5353\n",
      "Epoch 103/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 191.4920 - mae: 191.9904 - val_loss: 224.1930 - val_mae: 224.6927\n",
      "Epoch 104/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 190.0314 - mae: 190.5291 - val_loss: 222.4005 - val_mae: 222.8999\n",
      "Epoch 105/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 188.5531 - mae: 189.0516 - val_loss: 220.4839 - val_mae: 220.9821\n",
      "Epoch 106/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 187.0519 - mae: 187.5499 - val_loss: 218.5713 - val_mae: 219.0679\n",
      "Epoch 107/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 185.5785 - mae: 186.0770 - val_loss: 216.6634 - val_mae: 217.1577\n",
      "Epoch 108/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 184.0651 - mae: 184.5636 - val_loss: 214.6999 - val_mae: 215.1938\n",
      "Epoch 109/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 182.5488 - mae: 183.0474 - val_loss: 212.6875 - val_mae: 213.1819\n",
      "Epoch 110/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 181.0406 - mae: 181.5393 - val_loss: 210.7926 - val_mae: 211.2864\n",
      "Epoch 111/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 179.5800 - mae: 180.0779 - val_loss: 208.9371 - val_mae: 209.4335\n",
      "Epoch 112/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 178.1221 - mae: 178.6201 - val_loss: 207.0462 - val_mae: 207.5427\n",
      "Epoch 113/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 176.6566 - mae: 177.1546 - val_loss: 205.0835 - val_mae: 205.5807\n",
      "Epoch 114/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 175.2204 - mae: 175.7181 - val_loss: 203.1804 - val_mae: 203.6789\n",
      "Epoch 115/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 173.7773 - mae: 174.2753 - val_loss: 201.1737 - val_mae: 201.6718\n",
      "Epoch 116/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 172.3532 - mae: 172.8513 - val_loss: 199.1976 - val_mae: 199.6935\n",
      "Epoch 117/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 170.9559 - mae: 171.4539 - val_loss: 197.2047 - val_mae: 197.7018\n",
      "Epoch 118/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 169.5350 - mae: 170.0331 - val_loss: 195.2111 - val_mae: 195.7076\n",
      "Epoch 119/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 168.1445 - mae: 168.6428 - val_loss: 193.1917 - val_mae: 193.6889\n",
      "Epoch 120/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 166.7059 - mae: 167.2042 - val_loss: 191.0739 - val_mae: 191.5717\n",
      "Epoch 121/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 165.2596 - mae: 165.7575 - val_loss: 189.1408 - val_mae: 189.6395\n",
      "Epoch 122/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 163.8795 - mae: 164.3778 - val_loss: 187.3642 - val_mae: 187.8628\n",
      "Epoch 123/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 162.5168 - mae: 163.0147 - val_loss: 185.5139 - val_mae: 186.0130\n",
      "Epoch 124/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 161.1406 - mae: 161.6384 - val_loss: 183.6275 - val_mae: 184.1265\n",
      "Epoch 125/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 159.8217 - mae: 160.3198 - val_loss: 181.7960 - val_mae: 182.2951\n",
      "Epoch 126/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 158.4483 - mae: 158.9463 - val_loss: 179.8460 - val_mae: 180.3426\n",
      "Epoch 127/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 157.0560 - mae: 157.5538 - val_loss: 177.9114 - val_mae: 178.4064\n",
      "Epoch 128/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 155.6946 - mae: 156.1923 - val_loss: 176.0390 - val_mae: 176.5365\n",
      "Epoch 129/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 154.3672 - mae: 154.8647 - val_loss: 174.1378 - val_mae: 174.6352\n",
      "Epoch 130/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 153.0628 - mae: 153.5607 - val_loss: 172.3027 - val_mae: 172.7989\n",
      "Epoch 131/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 151.7651 - mae: 152.2624 - val_loss: 170.4092 - val_mae: 170.9065\n",
      "Epoch 132/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 150.4925 - mae: 150.9902 - val_loss: 168.6881 - val_mae: 169.1824\n",
      "Epoch 133/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 149.2269 - mae: 149.7246 - val_loss: 167.1452 - val_mae: 167.6409\n",
      "Epoch 134/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 147.9643 - mae: 148.4617 - val_loss: 165.5861 - val_mae: 166.0828\n",
      "Epoch 135/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 146.7022 - mae: 147.2001 - val_loss: 164.0069 - val_mae: 164.5051\n",
      "Epoch 136/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 145.4490 - mae: 145.9461 - val_loss: 162.4722 - val_mae: 162.9686\n",
      "Epoch 137/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 144.2171 - mae: 144.7141 - val_loss: 160.9477 - val_mae: 161.4445\n",
      "Epoch 138/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 143.0000 - mae: 143.4973 - val_loss: 159.4024 - val_mae: 159.8974\n",
      "Epoch 139/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 141.7751 - mae: 142.2729 - val_loss: 157.9376 - val_mae: 158.4343\n",
      "Epoch 140/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 140.5811 - mae: 141.0791 - val_loss: 156.5915 - val_mae: 157.0889\n",
      "Epoch 141/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 139.3973 - mae: 139.8950 - val_loss: 155.2560 - val_mae: 155.7525\n",
      "Epoch 142/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 138.2050 - mae: 138.7028 - val_loss: 153.9507 - val_mae: 154.4467\n",
      "Epoch 143/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 137.0428 - mae: 137.5408 - val_loss: 152.6490 - val_mae: 153.1465\n",
      "Epoch 144/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 135.9027 - mae: 136.4006 - val_loss: 151.2887 - val_mae: 151.7872\n",
      "Epoch 145/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 134.7098 - mae: 135.2079 - val_loss: 149.9168 - val_mae: 150.4154\n",
      "Epoch 146/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 133.5567 - mae: 134.0548 - val_loss: 148.5843 - val_mae: 149.0826\n",
      "Epoch 147/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 132.4605 - mae: 132.9591 - val_loss: 147.3265 - val_mae: 147.8228\n",
      "Epoch 148/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 131.3688 - mae: 131.8665 - val_loss: 146.1196 - val_mae: 146.6165\n",
      "Epoch 149/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 130.3223 - mae: 130.8202 - val_loss: 145.0482 - val_mae: 145.5457\n",
      "Epoch 150/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 129.2692 - mae: 129.7671 - val_loss: 143.9193 - val_mae: 144.4168\n",
      "Epoch 151/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 128.2366 - mae: 128.7344 - val_loss: 142.8405 - val_mae: 143.3380\n",
      "Epoch 152/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 127.2583 - mae: 127.7563 - val_loss: 141.7813 - val_mae: 142.2795\n",
      "Epoch 153/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 126.2971 - mae: 126.7953 - val_loss: 140.8712 - val_mae: 141.3699\n",
      "Epoch 154/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 125.3697 - mae: 125.8676 - val_loss: 140.0508 - val_mae: 140.5493\n",
      "Epoch 155/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 124.4610 - mae: 124.9589 - val_loss: 139.2887 - val_mae: 139.7856\n",
      "Epoch 156/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 123.5657 - mae: 124.0632 - val_loss: 138.5352 - val_mae: 139.0340\n",
      "Epoch 157/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 122.6813 - mae: 123.1787 - val_loss: 137.7808 - val_mae: 138.2798\n",
      "Epoch 158/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 121.8201 - mae: 122.3179 - val_loss: 137.0959 - val_mae: 137.5951\n",
      "Epoch 159/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 121.0163 - mae: 121.5140 - val_loss: 136.3720 - val_mae: 136.8687\n",
      "Epoch 160/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 120.1816 - mae: 120.6791 - val_loss: 135.6408 - val_mae: 136.1402\n",
      "Epoch 161/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 119.4067 - mae: 119.9048 - val_loss: 134.9751 - val_mae: 135.4749\n",
      "Epoch 162/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 118.6609 - mae: 119.1591 - val_loss: 134.2769 - val_mae: 134.7768\n",
      "Epoch 163/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 117.8985 - mae: 118.3965 - val_loss: 133.5888 - val_mae: 134.0887\n",
      "Epoch 164/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 117.1915 - mae: 117.6887 - val_loss: 132.9089 - val_mae: 133.4089\n",
      "Epoch 165/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 116.4949 - mae: 116.9926 - val_loss: 132.1847 - val_mae: 132.6847\n",
      "Epoch 166/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 115.8426 - mae: 116.3405 - val_loss: 131.5128 - val_mae: 132.0113\n",
      "Epoch 167/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 115.2332 - mae: 115.7313 - val_loss: 130.9591 - val_mae: 131.4559\n",
      "Epoch 168/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 114.6241 - mae: 115.1222 - val_loss: 130.3990 - val_mae: 130.8990\n",
      "Epoch 169/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 114.0230 - mae: 114.5215 - val_loss: 129.8307 - val_mae: 130.3307\n",
      "Epoch 170/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 113.4374 - mae: 113.9356 - val_loss: 129.2828 - val_mae: 129.7828\n",
      "Epoch 171/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 112.8646 - mae: 113.3623 - val_loss: 128.7387 - val_mae: 129.2370\n",
      "Epoch 172/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 112.3268 - mae: 112.8244 - val_loss: 128.1877 - val_mae: 128.6867\n",
      "Epoch 173/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 111.8050 - mae: 112.3022 - val_loss: 127.6219 - val_mae: 128.1219\n",
      "Epoch 174/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 111.3140 - mae: 111.8116 - val_loss: 127.0968 - val_mae: 127.5947\n",
      "Epoch 175/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 110.8406 - mae: 111.3383 - val_loss: 126.6523 - val_mae: 127.1523\n",
      "Epoch 176/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 110.3751 - mae: 110.8729 - val_loss: 126.1806 - val_mae: 126.6806\n",
      "Epoch 177/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 109.9317 - mae: 110.4290 - val_loss: 125.7335 - val_mae: 126.2335\n",
      "Epoch 178/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 109.5006 - mae: 109.9978 - val_loss: 125.2860 - val_mae: 125.7860\n",
      "Epoch 179/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 109.0889 - mae: 109.5866 - val_loss: 124.8398 - val_mae: 125.3382\n",
      "Epoch 180/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 108.7111 - mae: 109.2090 - val_loss: 124.3976 - val_mae: 124.8969\n",
      "Epoch 181/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 108.3378 - mae: 108.8355 - val_loss: 123.9685 - val_mae: 124.4685\n",
      "Epoch 182/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 107.9733 - mae: 108.4708 - val_loss: 123.5453 - val_mae: 124.0453\n",
      "Epoch 183/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 107.6136 - mae: 108.1113 - val_loss: 123.1219 - val_mae: 123.6206\n",
      "Epoch 184/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 107.2582 - mae: 107.7555 - val_loss: 122.7277 - val_mae: 123.2277\n",
      "Epoch 185/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 106.9257 - mae: 107.4237 - val_loss: 122.3477 - val_mae: 122.8477\n",
      "Epoch 186/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 106.5821 - mae: 107.0799 - val_loss: 121.9648 - val_mae: 122.4648\n",
      "Epoch 187/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 106.2587 - mae: 106.7567 - val_loss: 121.6215 - val_mae: 122.1215\n",
      "Epoch 188/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.9510 - mae: 106.4488 - val_loss: 121.2550 - val_mae: 121.7550\n",
      "Epoch 189/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.6404 - mae: 106.1385 - val_loss: 120.8868 - val_mae: 121.3868\n",
      "Epoch 190/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.3534 - mae: 105.8518 - val_loss: 120.5379 - val_mae: 121.0379\n",
      "Epoch 191/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.0770 - mae: 105.5751 - val_loss: 120.1862 - val_mae: 120.6862\n",
      "Epoch 192/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.7920 - mae: 105.2897 - val_loss: 119.8112 - val_mae: 120.3112\n",
      "Epoch 193/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.5363 - mae: 105.0345 - val_loss: 119.5067 - val_mae: 120.0067\n",
      "Epoch 194/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.2893 - mae: 104.7875 - val_loss: 119.1783 - val_mae: 119.6783\n",
      "Epoch 195/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 104.0360 - mae: 104.5336 - val_loss: 118.8411 - val_mae: 119.3411\n",
      "Epoch 196/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 103.7803 - mae: 104.2781 - val_loss: 118.5279 - val_mae: 119.0275\n",
      "Epoch 197/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.5315 - mae: 104.0297 - val_loss: 118.2905 - val_mae: 118.7905\n",
      "Epoch 198/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.2924 - mae: 103.7902 - val_loss: 118.0147 - val_mae: 118.5147\n",
      "Epoch 199/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.0616 - mae: 103.5597 - val_loss: 117.7565 - val_mae: 118.2565\n",
      "Epoch 200/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.8359 - mae: 103.3341 - val_loss: 117.4926 - val_mae: 117.9926\n",
      "Epoch 201/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.6140 - mae: 103.1121 - val_loss: 117.2279 - val_mae: 117.7279\n",
      "Epoch 202/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.3959 - mae: 102.8937 - val_loss: 116.9764 - val_mae: 117.4764\n",
      "Epoch 203/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.1873 - mae: 102.6855 - val_loss: 116.6750 - val_mae: 117.1726\n",
      "Epoch 204/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.9918 - mae: 102.4899 - val_loss: 116.4358 - val_mae: 116.9345\n",
      "Epoch 205/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.7919 - mae: 102.2903 - val_loss: 116.2076 - val_mae: 116.7057\n",
      "Epoch 206/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.5951 - mae: 102.0934 - val_loss: 115.9701 - val_mae: 116.4701\n",
      "Epoch 207/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.4038 - mae: 101.9023 - val_loss: 115.7202 - val_mae: 116.2200\n",
      "Epoch 208/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.2067 - mae: 101.7054 - val_loss: 115.4619 - val_mae: 115.9614\n",
      "Epoch 209/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.0147 - mae: 101.5133 - val_loss: 115.2421 - val_mae: 115.7421\n",
      "Epoch 210/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.8238 - mae: 101.3223 - val_loss: 115.0314 - val_mae: 115.5314\n",
      "Epoch 211/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.6301 - mae: 101.1281 - val_loss: 114.7998 - val_mae: 115.2998\n",
      "Epoch 212/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.4456 - mae: 100.9433 - val_loss: 114.6094 - val_mae: 115.1094\n",
      "Epoch 213/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.2686 - mae: 100.7658 - val_loss: 114.3688 - val_mae: 114.8688\n",
      "Epoch 214/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.0919 - mae: 100.5899 - val_loss: 114.1528 - val_mae: 114.6528\n",
      "Epoch 215/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.9179 - mae: 100.4155 - val_loss: 113.9294 - val_mae: 114.4294\n",
      "Epoch 216/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.7544 - mae: 100.2522 - val_loss: 113.7533 - val_mae: 114.2533\n",
      "Epoch 217/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.5862 - mae: 100.0844 - val_loss: 113.5595 - val_mae: 114.0595\n",
      "Epoch 218/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.4127 - mae: 99.9105 - val_loss: 113.3457 - val_mae: 113.8457\n",
      "Epoch 219/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.2422 - mae: 99.7397 - val_loss: 113.1175 - val_mae: 113.6175\n",
      "Epoch 220/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.0625 - mae: 99.5598 - val_loss: 112.8938 - val_mae: 113.3938\n",
      "Epoch 221/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.8873 - mae: 99.3846 - val_loss: 112.7073 - val_mae: 113.2073\n",
      "Epoch 222/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.7180 - mae: 99.2154 - val_loss: 112.4958 - val_mae: 112.9958\n",
      "Epoch 223/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.5500 - mae: 99.0473 - val_loss: 112.3224 - val_mae: 112.8224\n",
      "Epoch 224/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.3860 - mae: 98.8831 - val_loss: 112.1082 - val_mae: 112.6082\n",
      "Epoch 225/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.2334 - mae: 98.7307 - val_loss: 111.9152 - val_mae: 112.4152\n",
      "Epoch 226/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.0765 - mae: 98.5737 - val_loss: 111.7171 - val_mae: 112.2171\n",
      "Epoch 227/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.9284 - mae: 98.4262 - val_loss: 111.5498 - val_mae: 112.0498\n",
      "Epoch 228/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.7715 - mae: 98.2692 - val_loss: 111.3569 - val_mae: 111.8569\n",
      "Epoch 229/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.6277 - mae: 98.1258 - val_loss: 111.1842 - val_mae: 111.6842\n",
      "Epoch 230/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.4804 - mae: 97.9782 - val_loss: 110.9746 - val_mae: 111.4746\n",
      "Epoch 231/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.3240 - mae: 97.8218 - val_loss: 110.7888 - val_mae: 111.2888\n",
      "Epoch 232/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.1827 - mae: 97.6808 - val_loss: 110.5871 - val_mae: 111.0871\n",
      "Epoch 233/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.0353 - mae: 97.5336 - val_loss: 110.3910 - val_mae: 110.8910\n",
      "Epoch 234/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.9033 - mae: 97.4011 - val_loss: 110.2125 - val_mae: 110.7124\n",
      "Epoch 235/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.7611 - mae: 97.2588 - val_loss: 109.9879 - val_mae: 110.4877\n",
      "Epoch 236/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.6209 - mae: 97.1189 - val_loss: 109.8230 - val_mae: 110.3224\n",
      "Epoch 237/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.4974 - mae: 96.9951 - val_loss: 109.6265 - val_mae: 110.1253\n",
      "Epoch 238/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.3657 - mae: 96.8636 - val_loss: 109.4329 - val_mae: 109.9317\n",
      "Epoch 239/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.2424 - mae: 96.7401 - val_loss: 109.2542 - val_mae: 109.7521\n",
      "Epoch 240/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.1123 - mae: 96.6096 - val_loss: 109.0674 - val_mae: 109.5643\n",
      "Epoch 241/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 95.9869 - mae: 96.4846 - val_loss: 108.8953 - val_mae: 109.3927\n",
      "Epoch 242/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 95.8587 - mae: 96.3567 - val_loss: 108.7318 - val_mae: 109.2271\n",
      "Epoch 243/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.7380 - mae: 96.2362 - val_loss: 108.5553 - val_mae: 109.0507\n",
      "Epoch 244/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.6273 - mae: 96.1253 - val_loss: 108.3900 - val_mae: 108.8851\n",
      "Epoch 245/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.4971 - mae: 95.9956 - val_loss: 108.2029 - val_mae: 108.6987\n",
      "Epoch 246/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.3704 - mae: 95.8688 - val_loss: 108.0305 - val_mae: 108.5278\n",
      "Epoch 247/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.2344 - mae: 95.7331 - val_loss: 107.8904 - val_mae: 108.3890\n",
      "Epoch 248/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.1102 - mae: 95.6086 - val_loss: 107.7424 - val_mae: 108.2417\n",
      "Epoch 249/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.9913 - mae: 95.4898 - val_loss: 107.5895 - val_mae: 108.0890\n",
      "Epoch 250/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.8712 - mae: 95.3691 - val_loss: 107.4470 - val_mae: 107.9470\n",
      "Epoch 251/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.7531 - mae: 95.2515 - val_loss: 107.3059 - val_mae: 107.8059\n",
      "Epoch 252/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.6332 - mae: 95.1314 - val_loss: 107.1530 - val_mae: 107.6530\n",
      "Epoch 253/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.5165 - mae: 95.0148 - val_loss: 107.0319 - val_mae: 107.5319\n",
      "Epoch 254/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.4051 - mae: 94.9031 - val_loss: 106.8773 - val_mae: 107.3773\n",
      "Epoch 255/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.2915 - mae: 94.7894 - val_loss: 106.7490 - val_mae: 107.2490\n",
      "Epoch 256/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.1763 - mae: 94.6742 - val_loss: 106.6105 - val_mae: 107.1105\n",
      "Epoch 257/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.0681 - mae: 94.5656 - val_loss: 106.4582 - val_mae: 106.9582\n",
      "Epoch 258/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.9639 - mae: 94.4616 - val_loss: 106.3122 - val_mae: 106.8108\n",
      "Epoch 259/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.8613 - mae: 94.3589 - val_loss: 106.1814 - val_mae: 106.6814\n",
      "Epoch 260/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.7574 - mae: 94.2549 - val_loss: 106.0603 - val_mae: 106.5603\n",
      "Epoch 261/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.6522 - mae: 94.1496 - val_loss: 105.9357 - val_mae: 106.4356\n",
      "Epoch 262/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.5497 - mae: 94.0475 - val_loss: 105.8188 - val_mae: 106.3185\n",
      "Epoch 263/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.4440 - mae: 93.9424 - val_loss: 105.7238 - val_mae: 106.2235\n",
      "Epoch 264/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.3482 - mae: 93.8456 - val_loss: 105.6250 - val_mae: 106.1248\n",
      "Epoch 265/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.2407 - mae: 93.7380 - val_loss: 105.4898 - val_mae: 105.9896\n",
      "Epoch 266/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 93.1374 - mae: 93.6352 - val_loss: 105.3673 - val_mae: 105.8671\n",
      "Epoch 267/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 93.0427 - mae: 93.5407 - val_loss: 105.2383 - val_mae: 105.7381\n",
      "Epoch 268/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.9566 - mae: 93.4539 - val_loss: 105.1405 - val_mae: 105.6402\n",
      "Epoch 269/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.8619 - mae: 93.3598 - val_loss: 105.0688 - val_mae: 105.5658\n",
      "Epoch 270/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.7711 - mae: 93.2682 - val_loss: 104.9547 - val_mae: 105.4527\n",
      "Epoch 271/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.6783 - mae: 93.1753 - val_loss: 104.8578 - val_mae: 105.3568\n",
      "Epoch 272/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.5911 - mae: 93.0879 - val_loss: 104.7651 - val_mae: 105.2635\n",
      "Epoch 273/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.5136 - mae: 93.0109 - val_loss: 104.7037 - val_mae: 105.2020\n",
      "Epoch 274/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.4268 - mae: 92.9245 - val_loss: 104.6278 - val_mae: 105.1239\n",
      "Epoch 275/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.3446 - mae: 92.8418 - val_loss: 104.5440 - val_mae: 105.0390\n",
      "Epoch 276/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.2752 - mae: 92.7726 - val_loss: 104.4833 - val_mae: 104.9751\n",
      "Epoch 277/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.1917 - mae: 92.6894 - val_loss: 104.3982 - val_mae: 104.8931\n",
      "Epoch 278/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.1116 - mae: 92.6094 - val_loss: 104.3440 - val_mae: 104.8405\n",
      "Epoch 279/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.0339 - mae: 92.5316 - val_loss: 104.2783 - val_mae: 104.7753\n",
      "Epoch 280/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.9633 - mae: 92.4613 - val_loss: 104.1854 - val_mae: 104.6823\n",
      "Epoch 281/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.8892 - mae: 92.3869 - val_loss: 104.1260 - val_mae: 104.6227\n",
      "Epoch 282/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.8115 - mae: 92.3095 - val_loss: 104.0671 - val_mae: 104.5639\n",
      "Epoch 283/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.7322 - mae: 92.2302 - val_loss: 103.9915 - val_mae: 104.4886\n",
      "Epoch 284/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.6609 - mae: 92.1588 - val_loss: 103.9229 - val_mae: 104.4212\n",
      "Epoch 285/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.5831 - mae: 92.0810 - val_loss: 103.8472 - val_mae: 104.3459\n",
      "Epoch 286/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.5121 - mae: 92.0101 - val_loss: 103.7826 - val_mae: 104.2791\n",
      "Epoch 287/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.4385 - mae: 91.9367 - val_loss: 103.7301 - val_mae: 104.2271\n",
      "Epoch 288/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.3577 - mae: 91.8555 - val_loss: 103.6661 - val_mae: 104.1652\n",
      "Epoch 289/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.2895 - mae: 91.7875 - val_loss: 103.6293 - val_mae: 104.1292\n",
      "Epoch 290/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.2271 - mae: 91.7242 - val_loss: 103.5579 - val_mae: 104.0578\n",
      "Epoch 291/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.1576 - mae: 91.6549 - val_loss: 103.5034 - val_mae: 104.0031\n",
      "Epoch 292/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.0900 - mae: 91.5876 - val_loss: 103.4377 - val_mae: 103.9376\n",
      "Epoch 293/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.0212 - mae: 91.5190 - val_loss: 103.3815 - val_mae: 103.8815\n",
      "Epoch 294/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.9528 - mae: 91.4508 - val_loss: 103.3315 - val_mae: 103.8315\n",
      "Epoch 295/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.8927 - mae: 91.3903 - val_loss: 103.2955 - val_mae: 103.7955\n",
      "Epoch 296/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.8314 - mae: 91.3296 - val_loss: 103.2244 - val_mae: 103.7244\n",
      "Epoch 297/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.7734 - mae: 91.2713 - val_loss: 103.1296 - val_mae: 103.6296\n",
      "Epoch 298/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.7110 - mae: 91.2087 - val_loss: 103.0598 - val_mae: 103.5598\n",
      "Epoch 299/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.6504 - mae: 91.1480 - val_loss: 103.0058 - val_mae: 103.5058\n",
      "Epoch 300/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.5851 - mae: 91.0831 - val_loss: 102.9207 - val_mae: 103.4207\n",
      "Epoch 301/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.5298 - mae: 91.0280 - val_loss: 102.8686 - val_mae: 103.3686\n",
      "Epoch 302/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.4700 - mae: 90.9679 - val_loss: 102.8113 - val_mae: 103.3113\n",
      "Epoch 303/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.4168 - mae: 90.9145 - val_loss: 102.7592 - val_mae: 103.2592\n",
      "Epoch 304/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.3614 - mae: 90.8593 - val_loss: 102.7100 - val_mae: 103.2100\n",
      "Epoch 305/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.3084 - mae: 90.8066 - val_loss: 102.6843 - val_mae: 103.1843\n",
      "Epoch 306/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.2627 - mae: 90.7606 - val_loss: 102.6197 - val_mae: 103.1196\n",
      "Epoch 307/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.2040 - mae: 90.7021 - val_loss: 102.5566 - val_mae: 103.0565\n",
      "Epoch 308/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 90.1546 - mae: 90.6522 - val_loss: 102.5010 - val_mae: 103.0007\n",
      "Epoch 309/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 90.0992 - mae: 90.5967 - val_loss: 102.4470 - val_mae: 102.9466\n",
      "Epoch 310/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.0482 - mae: 90.5460 - val_loss: 102.3787 - val_mae: 102.8778\n",
      "Epoch 311/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.9995 - mae: 90.4969 - val_loss: 102.3203 - val_mae: 102.8188\n",
      "Epoch 312/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.9518 - mae: 90.4488 - val_loss: 102.2715 - val_mae: 102.7697\n",
      "Epoch 313/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.8926 - mae: 90.3900 - val_loss: 102.1948 - val_mae: 102.6927\n",
      "Epoch 314/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.8513 - mae: 90.3486 - val_loss: 102.1532 - val_mae: 102.6510\n",
      "Epoch 315/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.8012 - mae: 90.2980 - val_loss: 102.1104 - val_mae: 102.6078\n",
      "Epoch 316/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.7503 - mae: 90.2472 - val_loss: 102.0454 - val_mae: 102.5429\n",
      "Epoch 317/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.6981 - mae: 90.1950 - val_loss: 101.9756 - val_mae: 102.4737\n",
      "Epoch 318/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.6568 - mae: 90.1536 - val_loss: 101.9197 - val_mae: 102.4179\n",
      "Epoch 319/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.6082 - mae: 90.1047 - val_loss: 101.8444 - val_mae: 102.3417\n",
      "Epoch 320/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.5614 - mae: 90.0583 - val_loss: 101.7680 - val_mae: 102.2658\n",
      "Epoch 321/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.5216 - mae: 90.0187 - val_loss: 101.7449 - val_mae: 102.2430\n",
      "Epoch 322/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.4843 - mae: 89.9817 - val_loss: 101.6955 - val_mae: 102.1939\n",
      "Epoch 323/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.4378 - mae: 89.9354 - val_loss: 101.6773 - val_mae: 102.1762\n",
      "Epoch 324/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.4021 - mae: 89.8995 - val_loss: 101.6256 - val_mae: 102.1231\n",
      "Epoch 325/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.3597 - mae: 89.8564 - val_loss: 101.5992 - val_mae: 102.0987\n",
      "Epoch 326/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.3226 - mae: 89.8206 - val_loss: 101.5778 - val_mae: 102.0767\n",
      "Epoch 327/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.2888 - mae: 89.7865 - val_loss: 101.5261 - val_mae: 102.0243\n",
      "Epoch 328/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.2485 - mae: 89.7462 - val_loss: 101.4891 - val_mae: 101.9863\n",
      "Epoch 329/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.2135 - mae: 89.7111 - val_loss: 101.4474 - val_mae: 101.9453\n",
      "Epoch 330/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.1807 - mae: 89.6785 - val_loss: 101.4149 - val_mae: 101.9137\n",
      "Epoch 331/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.1422 - mae: 89.6395 - val_loss: 101.3850 - val_mae: 101.8844\n",
      "Epoch 332/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.1069 - mae: 89.6043 - val_loss: 101.3326 - val_mae: 101.8323\n",
      "Epoch 333/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.0713 - mae: 89.5686 - val_loss: 101.2833 - val_mae: 101.7831\n",
      "Epoch 334/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.0283 - mae: 89.5258 - val_loss: 101.2395 - val_mae: 101.7395\n",
      "Epoch 335/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.9919 - mae: 89.4893 - val_loss: 101.2029 - val_mae: 101.7028\n",
      "Epoch 336/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.9463 - mae: 89.4435 - val_loss: 101.1685 - val_mae: 101.6683\n",
      "Epoch 337/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.9038 - mae: 89.4014 - val_loss: 101.0801 - val_mae: 101.5765\n",
      "Epoch 338/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.8706 - mae: 89.3677 - val_loss: 101.0585 - val_mae: 101.5568\n",
      "Epoch 339/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.8381 - mae: 89.3354 - val_loss: 101.0261 - val_mae: 101.5236\n",
      "Epoch 340/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.8018 - mae: 89.2990 - val_loss: 100.9940 - val_mae: 101.4923\n",
      "Epoch 341/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.7673 - mae: 89.2647 - val_loss: 100.9697 - val_mae: 101.4693\n",
      "Epoch 342/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.7316 - mae: 89.2289 - val_loss: 100.9217 - val_mae: 101.4200\n",
      "Epoch 343/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.7020 - mae: 89.1990 - val_loss: 100.8944 - val_mae: 101.3907\n",
      "Epoch 344/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.6690 - mae: 89.1661 - val_loss: 100.8568 - val_mae: 101.3531\n",
      "Epoch 345/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.6355 - mae: 89.1328 - val_loss: 100.8078 - val_mae: 101.3037\n",
      "Epoch 346/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.6065 - mae: 89.1039 - val_loss: 100.7779 - val_mae: 101.2744\n",
      "Epoch 347/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5751 - mae: 89.0726 - val_loss: 100.7276 - val_mae: 101.2242\n",
      "Epoch 348/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5482 - mae: 89.0459 - val_loss: 100.7111 - val_mae: 101.2080\n",
      "Epoch 349/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5155 - mae: 89.0131 - val_loss: 100.6651 - val_mae: 101.1622\n",
      "Epoch 350/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4829 - mae: 88.9805 - val_loss: 100.6345 - val_mae: 101.1318\n",
      "Epoch 351/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4533 - mae: 88.9510 - val_loss: 100.6039 - val_mae: 101.1005\n",
      "Epoch 352/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4240 - mae: 88.9216 - val_loss: 100.5626 - val_mae: 101.0589\n",
      "Epoch 353/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3949 - mae: 88.8922 - val_loss: 100.5296 - val_mae: 101.0248\n",
      "Epoch 354/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3630 - mae: 88.8605 - val_loss: 100.4886 - val_mae: 100.9824\n",
      "Epoch 355/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3322 - mae: 88.8293 - val_loss: 100.4724 - val_mae: 100.9659\n",
      "Epoch 356/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3117 - mae: 88.8087 - val_loss: 100.4632 - val_mae: 100.9578\n",
      "Epoch 357/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.2840 - mae: 88.7815 - val_loss: 100.4138 - val_mae: 100.9102\n",
      "Epoch 358/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.2538 - mae: 88.7508 - val_loss: 100.3495 - val_mae: 100.8471\n",
      "Epoch 359/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.2297 - mae: 88.7267 - val_loss: 100.3024 - val_mae: 100.8000\n",
      "Epoch 360/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.2046 - mae: 88.7018 - val_loss: 100.2700 - val_mae: 100.7679\n",
      "Epoch 361/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.1772 - mae: 88.6748 - val_loss: 100.2456 - val_mae: 100.7425\n",
      "Epoch 362/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.1573 - mae: 88.6550 - val_loss: 100.1905 - val_mae: 100.6883\n",
      "Epoch 363/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.1305 - mae: 88.6282 - val_loss: 100.1619 - val_mae: 100.6612\n",
      "Epoch 364/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.1128 - mae: 88.6101 - val_loss: 100.1266 - val_mae: 100.6244\n",
      "Epoch 365/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.0821 - mae: 88.5795 - val_loss: 100.0990 - val_mae: 100.5960\n",
      "Epoch 366/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.0636 - mae: 88.5604 - val_loss: 100.0721 - val_mae: 100.5685\n",
      "Epoch 367/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.0283 - mae: 88.5259 - val_loss: 100.0711 - val_mae: 100.5689\n",
      "Epoch 368/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.0074 - mae: 88.5047 - val_loss: 100.0420 - val_mae: 100.5396\n",
      "Epoch 369/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.9867 - mae: 88.4841 - val_loss: 100.0431 - val_mae: 100.5410\n",
      "Epoch 370/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.9621 - mae: 88.4592 - val_loss: 99.9911 - val_mae: 100.4897\n",
      "Epoch 371/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.9400 - mae: 88.4372 - val_loss: 99.9603 - val_mae: 100.4586\n",
      "Epoch 372/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.9158 - mae: 88.4127 - val_loss: 99.9587 - val_mae: 100.4560\n",
      "Epoch 373/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.8997 - mae: 88.3969 - val_loss: 99.9527 - val_mae: 100.4502\n",
      "Epoch 374/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.8764 - mae: 88.3739 - val_loss: 99.9305 - val_mae: 100.4285\n",
      "Epoch 375/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.8575 - mae: 88.3547 - val_loss: 99.9241 - val_mae: 100.4215\n",
      "Epoch 376/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.8356 - mae: 88.3326 - val_loss: 99.8613 - val_mae: 100.3592\n",
      "Epoch 377/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.8135 - mae: 88.3106 - val_loss: 99.8309 - val_mae: 100.3283\n",
      "Epoch 378/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.7932 - mae: 88.2907 - val_loss: 99.7977 - val_mae: 100.2954\n",
      "Epoch 379/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.7714 - mae: 88.2686 - val_loss: 99.7765 - val_mae: 100.2742\n",
      "Epoch 380/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.7546 - mae: 88.2518 - val_loss: 99.7586 - val_mae: 100.2576\n",
      "Epoch 381/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.7345 - mae: 88.2320 - val_loss: 99.7293 - val_mae: 100.2276\n",
      "Epoch 382/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.7080 - mae: 88.2050 - val_loss: 99.7211 - val_mae: 100.2185\n",
      "Epoch 383/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.6927 - mae: 88.1898 - val_loss: 99.6762 - val_mae: 100.1738\n",
      "Epoch 384/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.6725 - mae: 88.1695 - val_loss: 99.6503 - val_mae: 100.1486\n",
      "Epoch 385/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.6517 - mae: 88.1488 - val_loss: 99.6486 - val_mae: 100.1467\n",
      "Epoch 386/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.6288 - mae: 88.1256 - val_loss: 99.6133 - val_mae: 100.1112\n",
      "Epoch 387/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.6106 - mae: 88.1076 - val_loss: 99.5857 - val_mae: 100.0852\n",
      "Epoch 388/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.5957 - mae: 88.0924 - val_loss: 99.5771 - val_mae: 100.0762\n",
      "Epoch 389/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.5720 - mae: 88.0690 - val_loss: 99.5530 - val_mae: 100.0517\n",
      "Epoch 390/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.5570 - mae: 88.0537 - val_loss: 99.5194 - val_mae: 100.0185\n",
      "Epoch 391/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.5364 - mae: 88.0334 - val_loss: 99.5157 - val_mae: 100.0150\n",
      "Epoch 392/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.5204 - mae: 88.0171 - val_loss: 99.5183 - val_mae: 100.0179\n",
      "Epoch 393/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.5027 - mae: 87.9992 - val_loss: 99.4824 - val_mae: 99.9809\n",
      "Epoch 394/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.4848 - mae: 87.9819 - val_loss: 99.4538 - val_mae: 99.9511\n",
      "Epoch 395/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.4677 - mae: 87.9652 - val_loss: 99.4090 - val_mae: 99.9069\n",
      "Epoch 396/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.4475 - mae: 87.9447 - val_loss: 99.4188 - val_mae: 99.9169\n",
      "Epoch 397/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.4334 - mae: 87.9305 - val_loss: 99.3827 - val_mae: 99.8812\n",
      "Epoch 398/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 87.4133 - mae: 87.9104 - val_loss: 99.3314 - val_mae: 99.8307\n",
      "Epoch 399/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.4045 - mae: 87.9016 - val_loss: 99.3339 - val_mae: 99.8337\n",
      "Epoch 400/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.3899 - mae: 87.8866 - val_loss: 99.2812 - val_mae: 99.7810\n"
     ]
    }
   ],
   "source": [
    "# Inicia o treinamento da rede\n",
    "redes_treinadas = neuralNetwork.fit(train_x, train_y, epochs = 400, batch_size = 32, validation_data = (validation_x, validation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.78101348876953\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imprime o menor erro absoluto médio encontrado\n",
    "print(min(neuralNetwork.history.history['val_mae']))\n",
    "\n",
    "# Plota o gráfico de convegência do treinamento\n",
    "plt.plot(neuralNetwork.history.history['val_mae'])\n",
    "plt.title('Histórico de Treinamento')\n",
    "plt.ylabel('Erro Absoluto')\n",
    "plt.xlabel('Épocas de treinamento')\n",
    "plt.legend(['Rede Componentes Principais'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 945us/step\n"
     ]
    }
   ],
   "source": [
    "# Insere os valores de teste na rede e coleta os resultados gerados pela rede\n",
    "predicts = neuralNetwork.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208.98341794456505, 104.72518029491518, 39.88775724418058, 5.099735368176985]\n",
      "[98.93194196302053, 5.111275467218138, 26.556840241627615, 6.589732284686923]\n",
      "[16.40008206287387, 52.977108708641296, 146.1830806459039, 7.636284233790685]\n",
      "[69.13011187658424, 51.73514550709392, 26.310427629140694, 16.007733193172772]\n",
      "[4.852498979257931, 13.121174470321561, 10.403710973970648, 20.429390405796816]\n",
      "[None, 35.030665692387934, 1.3592003988794599, 56.44828177787162]\n",
      "[7.3261878582553, 22.15327998592678, 17.740650477059532, 33.60968100861964]\n",
      "[76.58433134480306, 22.91581264246146, 5.146520067247417, 5.367347094772889]\n",
      "[7.719280674005116, 19.141512324116807, 16.01994200043903, 16.153958834134617]\n",
      "[67.03497764592625, 121.31730284943497, 50.420593054967455, 26.600998484027322]\n",
      "[None, 16.697304404490314, 18.659027357009236, 27.732764350043404]\n",
      "[298.89748464494744, 1958.0995430066746, 25.91763336751272, 73.52801428900825]\n",
      "[None, 188.06939214405958, 98.6390085048124, 4.284628591229839]\n",
      "[69.15223792510953, 23.446962997772715, 0.934278960930696, 2.62264329559949]\n",
      "[None, 34.41158598067061, 21.883130395013403, 9.752365638469827]\n",
      "[60.44886945421367, 27.495882179188964, 11.595957099853223, 25.235708880898176]\n",
      "[194.46525084096046, 2.88387997950426, 25.946059452888843, 26.101856627874632]\n",
      "[45.89971095355167, 74.14751669441442, 50.848237188550286, 3.882032825100806]\n",
      "[84.20503167765825, 8.823971448491454, 34.81439556466999, 29.58346616874621]\n",
      "[69.91216809756695, 17.642077619635362, 0.8244780126847768, 9.809624065052379]\n",
      "[55.112748328242034, 114.52475150579689, 10.887571600334924, 4.53404601478832]\n",
      "[None, 385.12737469221497, 110.77303190817598, 10.738706332656418]\n",
      "[None, 580.8202840202006, 80.8437198055945, 220.67162298387095]\n",
      "[26.639894837932314, 15.124230115684384, 197.26717797094827, 0.016744862432065216]\n",
      "[86.96600845884751, 1.4961790995794322, 38.08835807659218, 13.856440414617092]\n",
      "[54.8372304185908, 66.97086228904425, 64.97677387044857, 0.47129459168161886]\n",
      "[33.19434545228078, 13.077503699062204, 7.438919071684702, 17.010667588975696]\n",
      "[247.9639689127604, 22.6122590850405, 3.8072048588946417, 15.320028909822788]\n",
      "[5.769522756123722, 65.62247605917092, 23.2480425130489, 7.968285549209413]\n",
      "[None, 62.25846183241678, 3.8356624237478627, 10.026904233952157]\n",
      "[7.558073888298206, 140.20376316159536, 34.36489778083377, 11.903234704748376]\n",
      "[171.5396160442823, 27.66826464711216, 20.276686583876597, 5.810836637863005]\n",
      "[None, 19.371858629946836, 35.56714610641269, 10.597050904475552]\n",
      "[30.368424778494322, 36.27854573977361, 35.210877581856444, 1.1565603374291629]\n",
      "[28.426463462726126, 14.624305911811694, 18.43704322961078, 25.520638568281047]\n",
      "[None, 20.662176327009245, 11.00503187265292, 19.647825409544158]\n",
      "[7.015545863630625, 32.11196143943648, 16.71127518045322, 30.376896599830665]\n",
      "[41.41181374556526, 179.46542588050752, 40.68143518056889, 0.9176349762315468]\n",
      "[5.405441611757573, 49.51175680032077, 38.49893212904338, 5.150321937117737]\n",
      "[52.28011122410644, 50.0197564715457, 15.049668589966616, 4.486888988597973]\n",
      "[0.034377731277466586, 30.38040680749908, 15.049177845678665, 7.91726097323541]\n",
      "[None, 8.7228185241869, 45.09084916797533, 1.0619920932978295]\n",
      "[68.75524952276264, 22.737270744704922, 29.206071283430617, 10.54573759945046]\n",
      "[718.2590663218413, 207.89470048124707, 30.650249557491012, 10.829753659339545]\n",
      "[54.182180621054485, 37.682487556631365, 42.53287006036826, 12.024062241965193]\n",
      "[295.56332402966217, 14.91475223633127, 67.50845712518941, 3.7810589634092513]\n",
      "[165.30990082586305, 21.230753248244845, 4.18752289738802, 16.04071193271213]\n",
      "[82.44196177532139, 24.238948502445677, 7.3895944200084855, 12.906542011335784]\n",
      "[65.9862720632967, 74.53894799452966, 1.304971040580585, 3.9060600072957197]\n",
      "[None, 19.17104195018828, 4.094831059881031, 10.793218116876911]\n",
      "[55.07025746595938, 28.95106772965547, 21.912339564849418, 15.70982404344311]\n",
      "[91.40810797722077, 174.7953793689231, 129.3678182846678, 3.848156092226671]\n",
      "[54.42135088676514, 29.94871661215757, 35.38814538905047, 7.539363495291096]\n",
      "[79.97648621743335, 220.96760435254163, 90.6050875827637, 6.377753526150823]\n",
      "[3.586433392905508, 25.92344271898574, 52.791368616873136, 17.969476609002978]\n",
      "[103.13560211167734, 103.79607805173505, 18.086754460069848, 6.94781750676238]\n",
      "[160.48292874228932, 147.0811784219627, 28.242622767714483, 20.487495626659165]\n",
      "[41.73404319301279, 44.470246466607826, 28.62013297873458, 5.402715377026451]\n",
      "[7.7554167881066265, 18.785532383036337, 56.87062215613214, 54.424077515961024]\n",
      "[None, 15.989316426790682, 0.6641114039287275, 0.38021951534669207]\n",
      "[79.80167318382321, 309.5541580583063, 8.61280376764536, 35.55622703658344]\n",
      "[63.49687363395844, 66.73607230714403, 442.04893736733277, 27.838213593317573]\n",
      "[36.702443607739895, 37.8518233836441, 9.977775670034195, 47.20275411203903]\n",
      "[11.441977291281487, 19.4680168364661, 6.421190909933149, 18.64106383504747]\n",
      "[243.0522769199762, 68.91164272105325, 114.37352898021274, 10.10684525052919]\n",
      "[89.93363557338867, None, 14.614621842041888, 72.5055448470577]\n",
      "[49.229950085795885, 47.90610242188483, 46.61935986295218, 6.259936557969413]\n",
      "[86.77839785108023, 11.837677050578503, 39.50146470009561, 13.26097638419505]\n",
      "[None, 337.8602696561265, 19.98168188123847, 80.67809265929384]\n",
      "[None, 45.36861230097538, 50.4733774732134, 2.6749285312310835]\n",
      "[74.87612302801881, 31.72945043885888, 4.104466185107776, 8.75995342548077]\n",
      "[None, 76.95654619921434, 29.02339419003745, 85.95826960792226]\n",
      "[47.578652527786154, 7.747519328432261, 4.840416172847951, 17.936441721009814]\n",
      "[0.5123954065372482, 146.04288736979169, 66.01320733607832, 6.466907319568452]\n",
      "[22.74802154237718, 26.744398179945055, 21.105845328978447, 21.58064089847832]\n",
      "[None, None, 464.27857893827536, 40.02284794063358]\n",
      "[52.73949436992614, 2.860681649632499, 14.448569483108948, 22.77703403441374]\n",
      "[None, 13.412812487503754, 13.197249385865456, 20.98225986256319]\n",
      "[141.64418639657134, 27.842118659193588, 48.12214177137093, 1.2857956526208523]\n",
      "[17.097751230867654, 17.4726038870271, 11.612280671303843, 2.2030405435638603]\n",
      "[83.19981269172936, 14.60463895511074, 2.5229673686694305, 12.874434298316903]\n",
      "[74.01713557747682, 5.837161975107659, 15.70102726039361, 5.81816015919589]\n",
      "[8.685451600609758, 15.660234085821614, 188.20046297221333, 43.1956794691382]\n",
      "[82.96394044346606, 12.400455519363252, 59.4316314990202, 14.5688473131149]\n",
      "[504.2608409274815, 60.36010043949995, 318.44492851761885, 38.43532104492188]\n",
      "[34.67110059062191, 71.51264257209246, 44.08223144191222, 12.205593491760068]\n",
      "[70.0788693695682, 11.736876554065034, 13.800697939936798, 1305.2702470259233]\n",
      "[None, 29.903209391261438, 6.24303959252254, 49.61335555366848]\n",
      "[81.36367597232542, 144.91274997351005, 59.007846620526905, 11.15557003483441]\n",
      "[35.21218033401477, 506.47052894775084, 4.184676789403217, 43.80457781363224]\n",
      "[62.448576507649136, 76.72577842337188, 22.48687066975431, 8.41946072048611]\n",
      "[4.148399440291662, 2.6045735677083335, 17.392120366459032, 11.81940663141835]\n",
      "[79.32826207699758, 2.4126331663249445, 11.967048037256884, 15.291798368413398]\n",
      "[59.95366846332113, 128.34406683568128, 7.239532100031642, 6.6344018075980395]\n",
      "[50.43531585915396, 8.621875670841252, 22.893997330096564, 3.8400819177656724]\n",
      "[118.64104788214024, 63.595788604700346, 16.953269001244006, 18.636512756347656]\n",
      "[51.40706352936145, 34.37187158893004, 34.93100047839878, 28.281346263501465]\n",
      "[76.35485842164773, 38.73226796050127, 13.715179682932819, 7.150363723850052]\n",
      "[35.075018788921355, 61.406752009903556, 27.811108363797903, 14.591062609162575]\n",
      "[51.49935925722615, 165.18375025891186, 11.925678475906086, 11.841209118182842]\n",
      "[69.08865619406413, 65.71773436439476, 71.77886077330632, 27.26989152077631]\n",
      "[91.23439327274423, 41.407174321995676, 40.87275900526562, 31.02822808159722]\n",
      "[43.31014476789423, 9.328840066015124, 13.278549157004566, 0.02754483022350324]\n",
      "[20.797979525060047, 93.42431821812579, 27.529338541066075, 37.08179962940705]\n",
      "[None, 175.50766012344997, 61.457534787397094, 2.275560539720696]\n",
      "[56.0880483123305, 273.1652888284851, 72.02953291579416, 12.086753993646644]\n",
      "[8.663402805306616, 77.84581553981447, 27.90977643264417, 3.8950383449540773]\n",
      "[221.69459310190152, 41.499421772203945, 21.987834461668896, 25.575505059196036]\n",
      "[95.01450398719533, 136.7879942190645, 3.873368214241599, 0.25065151813158665]\n",
      "[59.22060546875, 36.33871272149498, 20.750262459259574, 34.972184669483866]\n",
      "[54.220689059953344, 14.886886545187709, 9.017482599805753, 13.893418541994235]\n",
      "[31.998218181479913, 504.35520743867903, 48.0089485860815, 22.51373761833801]\n",
      "[3.8576052352288412, 52.7585425806368, 8.721027740109966, 1.2777311307889923]\n",
      "[49.50230360161482, 45.428994168618196, 2.8387144812268494, 31.884174199067346]\n",
      "[64.10103863263103, 50.937828493501804, 23.194015943463928, 14.285365171123651]\n",
      "[66.55872913270073, 52.18063553777467, 28.490220325391984, 24.78950028734675]\n",
      "[34.08162352804164, 17.998035983518527, 31.211898558103368, 3.531473333185369]\n",
      "[None, 31.992415232564454, 25.27408360899707, 23.929535295175206]\n",
      "[46.758670865705774, 38.196279987868905, 1.9613458063655567, 28.878494684875243]\n",
      "[24.171059060677198, 90.64626083764664, 74.8792999746254, 97.01950073242188]\n",
      "[53.95466485140554, None, 96.99621508393747, 0.9726984872564164]\n",
      "[73.60770275755787, 21.62704467773437, 13.726705682645235, 16.682564195736436]\n",
      "[14.86994616309876, 64.83898859134347, 54.22344809827491, 33.68296018788512]\n",
      "[15.279520205689574, 303.43691697761193, 91.52017575528478, 18.555243142178746]\n",
      "[29.36562010123905, 28.11255221554211, 14.830468364597593, 16.995473288319594]\n",
      "[None, 8.109539877487638, 20.04181065185042, 7.616899762834821]\n",
      "[65.4039179460993, 22.99699021276831, 2.2008406884973675, 18.687589158345222]\n",
      "[None, 13.248092445939621, 27.502138490194767, 18.085388828007165]\n",
      "[None, 145.5742300917351, 22.612953394367118, 55.25465223524305]\n",
      "[None, None, 425.9568419637559, 40.77878444314861]\n",
      "[53.42042373550021, 49.3398363942038, 11.596424035388873, 26.12340708247951]\n",
      "[60.26558955205964, None, 60.91915173010858, 504.75509078414353]\n",
      "[76.20227115999093, 40.68085324173531, 107.8281036547507, 0.8446011147480238]\n",
      "[10.759753359561909, 62.52045338764949, 7.683437772975162, 11.148256036732764]\n",
      "[94.3169775037272, 38.346190692909964, 326.46818953682225, 33.33273867825019]\n",
      "[19.440969479587043, 42.12182846442028, 2.0497035546995135, 13.519571434637035]\n"
     ]
    }
   ],
   "source": [
    "errorPercentage = []\n",
    "\n",
    "# Calculo do tamanho do erro\n",
    "for i in range(test_y.shape[0]):\n",
    "    errorPercentage.append([])\n",
    "\n",
    "    for j in range(test_y.shape[1]):\n",
    "        erro = fabs(predicts[i][j] - test_y.iloc[i,j]) # Calcula o módulo da diferença entre o valor real e o gerado pela rede\n",
    "\n",
    "        if test_y.iloc[i,j] != 0: # Verifica se o valor real é diferente de zero para evitar divisão por zero\n",
    "            errorPercentage[i].append((erro / test_y.iloc[i,j])*100) # Calcula a porcentagem do tamanho do erro em relaçao ao valor real\n",
    "\n",
    "        else:\n",
    "            errorPercentage[i].append(None)  # Substitui a porcentagem com um valor nulo para ser descartado\n",
    "\n",
    "# Exibe o resultado\n",
    "for i in errorPercentage:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média do Erro em Porcetagem\n",
      "DOMPRECDOMEXP: 75.64%\n",
      "ADENSEXCDOMEXP: 87.12%\n",
      "ONUSEXCDOMEXP: 46.88%\n",
      "COABFAMDOMEXP: 33.17%\n"
     ]
    }
   ],
   "source": [
    "meanErrorPercentage = []\n",
    "\n",
    "# Calcula a média das porcentagens excluindo os valores nulos\n",
    "for i in range(test_y.shape[1]):\n",
    "    sum = 0\n",
    "    counter = test_y.shape[0]\n",
    "\n",
    "    for j in range(test_y.shape[0]):\n",
    "        if errorPercentage[j][i] == None:\n",
    "            counter -= 1\n",
    "\n",
    "        else:\n",
    "            sum += errorPercentage[j][i]\n",
    "\n",
    "    meanErrorPercentage.append(sum/counter)\n",
    "\n",
    "print(\"Média do Erro em Porcetagem\")\n",
    "for i in range(len(meanErrorPercentage)):\n",
    "    print(\"{}: {:.2f}%\".format(saidasDomicilios[i], meanErrorPercentage[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
